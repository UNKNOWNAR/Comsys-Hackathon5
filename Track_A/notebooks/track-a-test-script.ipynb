{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1504587,"sourceType":"datasetVersion","datasetId":885648},{"sourceId":12361947,"sourceType":"datasetVersion","datasetId":7794032}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Parameters ---#\nIMAGE_SIZE = (224, 224)\nIMG_SHAPE = IMAGE_SIZE + (3,)\nNUM_CLASSES = 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Focal Loss Function (must match training) ---#\ndef focal_loss(gamma=2.0, alpha=0.75):\n    def loss(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        weight = alpha * y_true * tf.pow(1 - y_pred, gamma)\n        return tf.reduce_sum(weight * cross_entropy, axis=1)\n    return loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Rebuild Model Architecture ---#\ndef build_model():\n    inputs = tf.keras.Input(shape=IMG_SHAPE)\n    base_model = EfficientNetB0(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=IMG_SHAPE,\n        pooling='avg'\n    )(inputs)\n    x = layers.Dropout(0.5)(base_model)\n    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs, outputs)\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Load Model and Weights ---#\nmodel = build_model()\nmodel.load_weights('/kaggle/input/test12/gender_classifier_full.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Load the saved threshold ---#\nwith open('/kaggle/input/test12/female_threshold.txt', 'r') as f:\n    female_thresh = float(f.read().strip())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Function to Preprocess and Predict on Test Images ---#\ndef load_and_preprocess_image(img_path):\n    img = tf.keras.utils.load_img(img_path, target_size=IMAGE_SIZE)\n    img = tf.keras.utils.img_to_array(img)\n    img = img / 255.0\n    return img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_confusion_matrix(y_true, y_pred, class_names):\n    cm = confusion_matrix(y_true, y_pred)\n    # Calculate max length for formatting\n    max_len = max(len(name) for name in class_names) + 5\n    \n    # Create header\n    header = \" \" * max_len + \"| \" + \" | \".join([f\"Predicted {name}\" for name in class_names])\n    separator = \"-\" * len(header)\n    \n    # Create rows\n    rows = []\n    for i, true_name in enumerate(class_names):\n        row = f\"True {true_name}\".ljust(max_len) + \"| \"\n        row += \" | \".join([f\"{cm[i,j]:<{len('Predicted ' + class_names[j])}}\" for j in range(len(class_names))])\n        rows.append(row)\n    \n    # Print matrix\n    print(\"\\nConfusion Matrix:\")\n    print(header)\n    print(separator)\n    for row in rows:\n        print(row)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_and_evaluate(female_folder, male_folder, female_thresh):\n    y_true = []\n    y_pred = []\n    results = []\n\n    # Female images\n    image_files = [f for f in os.listdir(female_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n    for fname in image_files:\n        img_path = os.path.join(female_folder, fname)\n        img = load_and_preprocess_image(img_path)\n        img_batch = np.expand_dims(img, axis=0)\n        pred = model.predict(img_batch, verbose=0)\n        female_prob = pred[0][0]\n        pred_class = 0 if female_prob >= female_thresh else 1  # 0: Female, 1: Male\n        y_true.append(0)  # 0: Female\n        y_pred.append(pred_class)\n        results.append({\n            'filename': fname,\n            'true_class': 'Female',\n            'predicted_class': 'Female' if pred_class == 0 else 'Male',\n            'prob_female': float(pred[0][0]),\n            'prob_male': float(pred[0][1])\n        })\n\n    # Male images\n    image_files = [f for f in os.listdir(male_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n    for fname in image_files:\n        img_path = os.path.join(male_folder, fname)\n        img = load_and_preprocess_image(img_path)\n        img_batch = np.expand_dims(img, axis=0)\n        pred = model.predict(img_batch, verbose=0)\n        female_prob = pred[0][0]\n        pred_class = 0 if female_prob >= female_thresh else 1  # 0: Female, 1: Male\n        y_true.append(1)  # 1: Male\n        y_pred.append(pred_class)\n        results.append({\n            'filename': fname,\n            'true_class': 'Male',\n            'predicted_class': 'Female' if pred_class == 0 else 'Male',\n            'prob_female': float(pred[0][0]),\n            'prob_male': float(pred[0][1])\n        })\n    return y_true, y_pred, results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"female_folder = '/kaggle/input/male-and-female-faces-dataset/Male and Female face dataset/Female Faces'  # PUT TEST FILES For FEMALE HERE\nmale_folder = '/kaggle/input/male-and-female-faces-dataset/Male and Female face dataset/Male Faces'      # or PUT TEST FILES For MALE HERE\n\ny_true, y_pred, results = predict_and_evaluate(female_folder, male_folder, female_thresh)\n\n# Print classification report\nclass_names = ['Female', 'Male']\nprint(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n\n# Print confusion matrix\nprint_confusion_matrix(y_true, y_pred, class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}